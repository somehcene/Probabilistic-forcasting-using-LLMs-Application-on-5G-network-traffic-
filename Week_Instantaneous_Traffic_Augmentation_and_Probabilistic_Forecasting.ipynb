{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e01401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 2.4.2\n",
      "Pandas: 3.0.0\n",
      "Torch: 2.10.0+cpu\n",
      "Chronos OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from chronos import Chronos2Pipeline, ChronosBoltPipeline\n",
    "\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Chronos OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91091337",
   "metadata": {},
   "source": [
    "# Instantaneous Traffic Generation and Probabilistic Forecasting\n",
    "\n",
    "## 1. Motivation\n",
    "\n",
    "The original Bouygues telecom dataset provides traffic measurements averaged over **coarse time intervals** (one week per observation).  \n",
    "While such averages are sufficient to capture long-term traffic trends, they fail to represent the **short-term variability and burstiness** that are critical for network dimensioning and worst-case analysis.\n",
    "\n",
    "In practice, telecom networks operate at much finer time resolutions (e.g., 5-minute intervals), where traffic demand exhibits rapid fluctuations due to user activity, mobility, and application behavior.  \n",
    "As a result, forecasting only averaged traffic values is not sufficient to evaluate the ability of forecasting models to anticipate peak demand.\n",
    "\n",
    "The objective of this notebook is therefore to:\n",
    "- reconstruct **instantaneous traffic signals** from weekly averages using a principled data augmentation framework,\n",
    "- and evaluate **probabilistic forecasting models** on this fine-grained traffic.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Assumption on Traffic Measurements\n",
    "\n",
    "We assume that each weekly traffic value corresponds to an average over multiple **5-minute measurements**.\n",
    "\n",
    "Formally, for a given antenna sector $s$ and week $w$, the observed traffic value $\\bar{T}_s(w)$ can be written as:\n",
    "\n",
    "$$\n",
    "\\bar{T}_s(w) = \\frac{1}{N} \\sum_{k=1}^{N} T_s(w, k)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $T_s(w, k)$ denotes the instantaneous traffic at 5-minute slot $k$,\n",
    "- $N = \\frac{7 \\times 24 \\times 60}{5} = 2016$ is the number of 5-minute slots per week.\n",
    "\n",
    "The instantaneous values $T_s(w, k)$ are not observed and must be generated.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Data Augmentation Framework\n",
    "\n",
    "To generate realistic instantaneous traffic, we follow the **conceptual framework described in Section II-C and Figure 6(a)** of the reference paper.\n",
    "\n",
    "The key idea is to reconstruct a fine-grained traffic signal that:\n",
    "- preserves the **mean traffic level** observed in the dataset,\n",
    "- exhibits **bursty ON/OFF behavior** typical of real telecom traffic,\n",
    "- and introduces short-term variability on top of long-term trends.\n",
    "\n",
    "Rather than explicitly modeling users and packet arrivals, we adopt a simplified stochastic approach that reproduces the essential statistical properties of real traffic.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Instantaneous Traffic Generation Model\n",
    "\n",
    "For each sector and each week, instantaneous traffic is generated using the following steps:\n",
    "\n",
    "### 4.1 Fine-Grained Time Axis\n",
    "\n",
    "Each weekly observation is divided into $N = 2016$ pseudo 5-minute time slots, representing instantaneous traffic measurements.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.2 Bursty Activity Modeling (ON/OFF Process)\n",
    "\n",
    "Traffic activity is modeled using a binary ON/OFF process:\n",
    "\n",
    "$$\n",
    "B(k) \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $B(k) = 1$ indicates an active (burst) period,\n",
    "- $B(k) = 0$ indicates an inactive or low-traffic period.\n",
    "\n",
    "This process introduces realistic traffic intermittency and burstiness.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.3 Raw Instantaneous Traffic Generation\n",
    "\n",
    "During active periods, instantaneous traffic values are drawn from a random distribution:\n",
    "\n",
    "$$\n",
    "X(k) =\n",
    "\\begin{cases}\n",
    "\\epsilon_k, & \\text{if } B(k) = 1 \\\\\n",
    "0, & \\text{if } B(k) = 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\epsilon_k$ is a positive random variable capturing short-term traffic fluctuations.\n",
    "\n",
    "This step introduces variability and peak values that are absent from averaged measurements.\n",
    "\n",
    "---\n",
    "\n",
    "### 4.4 Mean Preservation via Normalization\n",
    "\n",
    "To ensure consistency with the original dataset, the generated instantaneous traffic is normalized so that its average matches the observed weekly value:\n",
    "\n",
    "$$\n",
    "T(k) = \\frac{\\bar{T}_s(w)}{\\frac{1}{N} \\sum_{k=1}^{N} X(k)} \\cdot X(k)\n",
    "$$\n",
    "\n",
    "This guarantees that:\n",
    "- the weekly average traffic remains unchanged,\n",
    "- while instantaneous variability is explicitly introduced.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Resulting Traffic Characteristics\n",
    "\n",
    "The resulting instantaneous traffic signal:\n",
    "- follows the long-term trend of the original weekly data,\n",
    "- exhibits realistic short-term fluctuations and bursts,\n",
    "- produces higher peak values relevant for network dimensioning.\n",
    "\n",
    "This behavior is consistent with the qualitative illustration shown in Figure 6(a) of the reference paper.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Forecasting Objective\n",
    "\n",
    "The augmented dataset enables a new forecasting task:\n",
    "\n",
    "> **Given historical instantaneous traffic measurements, predict future instantaneous traffic values.**\n",
    "\n",
    "Both **large language models (Chronos-2)** and **trained LSTM baselines** are evaluated under this setting.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Evaluation Metrics\n",
    "\n",
    "Two complementary metrics are used:\n",
    "\n",
    "- **Root Mean Square Error (RMSE)**  \n",
    "  Evaluates point forecast accuracy using the median prediction.\n",
    "\n",
    "- **Pinball Loss (Quantile Loss)**  \n",
    "  Evaluates probabilistic forecasting accuracy for high quantiles (e.g., $q = 0.9$), which are critical for worst-case network dimensioning.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Summary\n",
    "\n",
    "By reconstructing fine-grained instantaneous traffic from coarse averages, this notebook enables a realistic evaluation of probabilistic forecasting models in a telecom context.  \n",
    "This approach bridges the gap between averaged datasets and operational network requirements, where anticipating peak demand is essential.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5439fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e448f6",
   "metadata": {},
   "source": [
    "#### Function to save longs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a647f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "RESULTS_CSV = \"results_instantaneous_lstm_vs_chronos.csv\"\n",
    "\n",
    "def log_run(row: dict, path=RESULTS_CSV):\n",
    "    row = dict(row)\n",
    "    row[\"timestamp_run\"] = datetime.now().isoformat(timespec=\"seconds\")\n",
    "    df_row = pd.DataFrame([row])\n",
    "    if os.path.exists(path):\n",
    "        df_row.to_csv(path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "def load_runs(path=RESULTS_CSV):\n",
    "    return pd.read_csv(path) if os.path.exists(path) else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5288994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secteur</th>\n",
       "      <th>site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>trafic_mbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T70721A</td>\n",
       "      <td>T70721</td>\n",
       "      <td>lundi 18 juin 2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T70721B</td>\n",
       "      <td>T70721</td>\n",
       "      <td>lundi 18 juin 2018</td>\n",
       "      <td>1.788239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T70721C</td>\n",
       "      <td>T70721</td>\n",
       "      <td>lundi 18 juin 2018</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T70722A</td>\n",
       "      <td>T70722</td>\n",
       "      <td>lundi 18 juin 2018</td>\n",
       "      <td>4.437942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T70722B</td>\n",
       "      <td>T70722</td>\n",
       "      <td>lundi 18 juin 2018</td>\n",
       "      <td>10.885752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secteur    site              tstamp  trafic_mbps\n",
       "0  T70721A  T70721  lundi 18 juin 2018     0.000000\n",
       "1  T70721B  T70721  lundi 18 juin 2018     1.788239\n",
       "2  T70721C  T70721  lundi 18 juin 2018     0.000000\n",
       "3  T70722A  T70722  lundi 18 juin 2018     4.437942\n",
       "4  T70722B  T70722  lundi 18 juin 2018    10.885752"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/histo_trafic.csv\",\n",
    "    sep=\";\",\n",
    "    encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f32796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tstamp_clean\"] = df[\"tstamp\"].str.replace(\n",
    "    r\"^[a-zA-Zéûîôàç]+\\s+\", \"\", regex=True\n",
    ")\n",
    "\n",
    "month_map = {\n",
    "    \"janvier\": \"January\",\n",
    "    \"février\": \"February\",\n",
    "    \"mars\": \"March\",\n",
    "    \"avril\": \"April\",\n",
    "    \"mai\": \"May\",\n",
    "    \"juin\": \"June\",\n",
    "    \"juillet\": \"July\",\n",
    "    \"août\": \"August\",\n",
    "    \"septembre\": \"September\",\n",
    "    \"octobre\": \"October\",\n",
    "    \"novembre\": \"November\",\n",
    "    \"décembre\": \"December\"\n",
    "}\n",
    "\n",
    "for fr, en in month_map.items():\n",
    "    df[\"tstamp_clean\"] = df[\"tstamp_clean\"].str.replace(fr, en, regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5435da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tstamp\"] = pd.to_datetime(df[\"tstamp_clean\"], format=\"%d %B %Y\")\n",
    "df = df.drop(columns=\"tstamp_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc8ce17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secteur</th>\n",
       "      <th>site</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>trafic_mbps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0.263481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.066913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-26</td>\n",
       "      <td>0.062066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-12-03</td>\n",
       "      <td>0.084320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-12-10</td>\n",
       "      <td>0.047759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      secteur    site     tstamp  trafic_mbps\n",
       "1575  T36870A  T36870 2018-11-12     0.263481\n",
       "1658  T36870A  T36870 2018-11-19     0.066913\n",
       "1741  T36870A  T36870 2018-11-26     0.062066\n",
       "1824  T36870A  T36870 2018-12-03     0.084320\n",
       "1907  T36870A  T36870 2018-12-10     0.047759"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values([\"secteur\", \"tstamp\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fc82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SLOTS = 2016          # 5-minute slots per week\n",
    "P_ON = 0.25             # burst probability\n",
    "NOISE_STD_RATIO = 0.5   # relative variability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11c7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instantaneous_traffic(weekly_mean,\n",
    "                                    n_slots=N_SLOTS,\n",
    "                                    p_on=P_ON,\n",
    "                                    noise_std_ratio=NOISE_STD_RATIO):\n",
    "    \"\"\"\n",
    "    Generate instantaneous traffic from a weekly average value.\n",
    "    \"\"\"\n",
    "    # ON / OFF activity\n",
    "    on_off = np.random.binomial(1, p_on, size=n_slots)\n",
    "\n",
    "    # Raw traffic during ON periods\n",
    "    noise_std = noise_std_ratio * weekly_mean\n",
    "    raw = np.random.normal(\n",
    "        loc=weekly_mean,\n",
    "        scale=noise_std,\n",
    "        size=n_slots\n",
    "    )\n",
    "\n",
    "    raw = np.clip(raw, a_min=0, a_max=None)\n",
    "\n",
    "    X = on_off * raw\n",
    "\n",
    "    # Mean preservation\n",
    "    if X.mean() > 0:\n",
    "        T = weekly_mean * X / X.mean()\n",
    "    else:\n",
    "        T = np.zeros_like(X)\n",
    "\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b83951b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secteur</th>\n",
       "      <th>site</th>\n",
       "      <th>week</th>\n",
       "      <th>slot</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.891498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secteur    site       week  slot   traffic\n",
       "0  T36870A  T36870 2018-11-12     0  0.000000\n",
       "1  T36870A  T36870 2018-11-12     1  0.891498\n",
       "2  T36870A  T36870 2018-11-12     2  0.000000\n",
       "3  T36870A  T36870 2018-11-12     3  0.000000\n",
       "4  T36870A  T36870 2018-11-12     4  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instantaneous_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    inst_signal = generate_instantaneous_traffic(row[\"trafic_mbps\"])\n",
    "\n",
    "    for k, value in enumerate(inst_signal):\n",
    "        instantaneous_rows.append({\n",
    "            \"secteur\": row[\"secteur\"],\n",
    "            \"site\": row[\"site\"],\n",
    "            \"week\": row[\"tstamp\"],\n",
    "            \"slot\": k,\n",
    "            \"traffic\": value\n",
    "        })\n",
    "\n",
    "instantaneous_df = pd.DataFrame(instantaneous_rows)\n",
    "instantaneous_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c902577d",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "This process took around 14 minutes.\n",
    "\n",
    "That’s normal because: 2016 slots × ~25k rows ≈ 50 million points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c706897e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.448600e+04\n",
       "mean     3.529467e-17\n",
       "std      3.547446e-15\n",
       "min     -5.684342e-14\n",
       "25%      0.000000e+00\n",
       "50%      0.000000e+00\n",
       "75%      0.000000e+00\n",
       "max      2.842171e-14\n",
       "Name: error, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = (\n",
    "    instantaneous_df\n",
    "    .groupby([\"secteur\", \"week\"])[\"traffic\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "        df[[\"secteur\", \"tstamp\", \"trafic_mbps\"]],\n",
    "        left_on=[\"secteur\", \"week\"],\n",
    "        right_on=[\"secteur\", \"tstamp\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    ")\n",
    "\n",
    "check[\"error\"] = check[\"traffic\"] - check[\"trafic_mbps\"]\n",
    "check[\"error\"].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29109a6e",
   "metadata": {},
   "source": [
    "we see that: \n",
    "  - Mean error ≈ 0 up to floating-point precision\n",
    "  - Errors are on the order of 1e-14 → machine epsilon\n",
    "  - 25/50/75% at 0 → expected with floating noise\n",
    "  \n",
    "The generated instantaneous traffic preserves the original weekly average up to numerical precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a9d22",
   "metadata": {},
   "source": [
    "**Sanity check.**  \n",
    "The average of the generated instantaneous traffic matches the original weekly traffic values up to numerical precision (mean error ≈ $10^{-15}$), confirming that the augmentation preserves long-term traffic statistics while introducing short-term variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfb1fa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secteur</th>\n",
       "      <th>site</th>\n",
       "      <th>week</th>\n",
       "      <th>slot</th>\n",
       "      <th>traffic</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-11-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.891498</td>\n",
       "      <td>2018-11-12 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-11-12 00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-11-12 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018-11-12 00:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secteur    site       week  slot   traffic           timestamp\n",
       "0  T36870A  T36870 2018-11-12     0  0.000000 2018-11-12 00:00:00\n",
       "1  T36870A  T36870 2018-11-12     1  0.891498 2018-11-12 00:05:00\n",
       "2  T36870A  T36870 2018-11-12     2  0.000000 2018-11-12 00:10:00\n",
       "3  T36870A  T36870 2018-11-12     3  0.000000 2018-11-12 00:15:00\n",
       "4  T36870A  T36870 2018-11-12     4  0.000000 2018-11-12 00:20:00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instantaneous_df = instantaneous_df.copy()\n",
    "\n",
    "# Each slot = 5 minutes\n",
    "instantaneous_df[\"timestamp\"] = (\n",
    "    instantaneous_df[\"week\"]\n",
    "    + pd.to_timedelta(instantaneous_df[\"slot\"] * 5, unit=\"min\")\n",
    ")\n",
    "\n",
    "instantaneous_df = instantaneous_df.sort_values(\n",
    "    [\"secteur\", \"timestamp\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "instantaneous_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f639f7",
   "metadata": {},
   "source": [
    "we do NOT want to feed 50M points to Chronos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "637c5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we keep only the last week per sector\n",
    "week_max = instantaneous_df.groupby(\"secteur\")[\"week\"].transform(\"max\")\n",
    "last_week_df = instantaneous_df.loc[instantaneous_df[\"week\"] == week_max].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6434396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536256</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536257</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-01 00:05:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536258</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-01 00:10:00</td>\n",
       "      <td>50.060216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536259</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-01 00:15:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536260</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-01 00:20:00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id           timestamp     target\n",
       "536256  T36870A 2024-01-01 00:00:00   0.000000\n",
       "536257  T36870A 2024-01-01 00:05:00   0.000000\n",
       "536258  T36870A 2024-01-01 00:10:00  50.060216\n",
       "536259  T36870A 2024-01-01 00:15:00   0.000000\n",
       "536260  T36870A 2024-01-01 00:20:00   0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chronos_df = last_week_df.rename(columns={\"secteur\":\"id\", \"traffic\":\"target\"})[[\"id\",\"timestamp\",\"target\"]]\n",
    "\n",
    "\n",
    "chronos_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b69faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'timestamp', 'target'], dtype='str')\n",
      "Index(['id', 'timestamp', 'target'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "# mark last row per id\n",
    "is_last = chronos_df.groupby(\"id\")[\"timestamp\"].transform(\"max\") == chronos_df[\"timestamp\"]\n",
    "\n",
    "context_df = chronos_df.loc[~is_last].copy()\n",
    "test_df    = chronos_df.loc[is_last].copy()\n",
    "\n",
    "print(context_df.columns)\n",
    "print(test_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e318a7d976648e0b6f087f568be736e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sherif\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sherif\\.cache\\huggingface\\hub\\models--amazon--chronos-2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eae7c3a22b04af482a758893f45a927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from chronos import Chronos2Pipeline\n",
    "\n",
    "pipeline = Chronos2Pipeline.from_pretrained(\n",
    "    \"amazon/chronos-2\",\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d93817e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sherif\\miniconda3\\Lib\\site-packages\\chronos\\chronos2\\dataset.py:89: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:219.)\n",
      "  task_target = torch.from_numpy(task_target)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target_name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>target</td>\n",
       "      <td>0.243373</td>\n",
       "      <td>0.243373</td>\n",
       "      <td>73.116631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T36870B</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>target</td>\n",
       "      <td>0.087078</td>\n",
       "      <td>0.087078</td>\n",
       "      <td>24.401529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T70721A</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>target</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>19.745817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T70721B</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>target</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>18.486391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T70721C</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>target</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>6.536980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           timestamp target_name  predictions       0.5        0.9\n",
       "0  T36870A 2024-01-07 23:55:00      target     0.243373  0.243373  73.116631\n",
       "1  T36870B 2024-01-07 23:55:00      target     0.087078  0.087078  24.401529\n",
       "2  T70721A 2024-01-07 23:55:00      target     0.124113  0.124113  19.745817\n",
       "3  T70721B 2024-01-07 23:55:00      target     0.094389  0.094389  18.486391\n",
       "4  T70721C 2024-01-07 23:55:00      target     0.026159  0.026159   6.536980"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pipeline.predict_df(\n",
    "    context_df,\n",
    "    prediction_length=1,\n",
    "    id_column=\"id\",\n",
    "    timestamp_column=\"timestamp\",\n",
    "    target=\"target\",\n",
    "    quantile_levels=[0.5, 0.9],\n",
    ")\n",
    "\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3800025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        str\n",
       "timestamp      datetime64[us]\n",
       "target_name               str\n",
       "predictions           float32\n",
       "0.5                   float32\n",
       "0.9                   float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()\n",
    "pred_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed9d51bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_q50</th>\n",
       "      <th>pred_q90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>97.373674</td>\n",
       "      <td>0.243373</td>\n",
       "      <td>73.116631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T36870B</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087078</td>\n",
       "      <td>24.401529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T70721A</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124113</td>\n",
       "      <td>19.745817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T70721B</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094389</td>\n",
       "      <td>18.486391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T70721C</td>\n",
       "      <td>2024-01-07 23:55:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>6.536980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id           timestamp     target  pred_q50   pred_q90\n",
       "0  T36870A 2024-01-07 23:55:00  97.373674  0.243373  73.116631\n",
       "1  T36870B 2024-01-07 23:55:00   0.000000  0.087078  24.401529\n",
       "2  T70721A 2024-01-07 23:55:00   0.000000  0.124113  19.745817\n",
       "3  T70721B 2024-01-07 23:55:00   0.000000  0.094389  18.486391\n",
       "4  T70721C 2024-01-07 23:55:00   0.000000  0.026159   6.536980"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = test_df.merge(\n",
    "    pred_df[[\"id\", \"0.5\", \"0.9\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "eval_df = eval_df.rename(columns={\"0.5\": \"pred_q50\", \"0.9\": \"pred_q90\"})\n",
    "\n",
    "eval_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e54238e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(112.9518842328321), np.float64(21.52474884773724))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_chronos = np.sqrt(\n",
    "    np.mean((eval_df[\"pred_q50\"] - eval_df[\"target\"]) ** 2)\n",
    ")\n",
    "\n",
    "pinball_chronos_q90 = np.mean(\n",
    "    np.maximum(\n",
    "        0.9 * (eval_df[\"target\"] - eval_df[\"pred_q90\"]),\n",
    "        0.1 * (eval_df[\"pred_q90\"] - eval_df[\"target\"])\n",
    "    )\n",
    ")\n",
    "\n",
    "rmse_chronos, pinball_chronos_q90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e758970",
   "metadata": {},
   "source": [
    "The RMSE obtained on instantaneous traffic is significantly higher than on weekly averaged traffic.\n",
    "This increase is expected, as instantaneous traffic exhibits high variance and bursty behavior that is absent from averaged measurements.\n",
    "Consequently, point-wise metrics such as RMSE become less informative, motivating the use of probabilistic metrics such as the pinball loss for worst-case evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e00a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_run({\n",
    "    \"model\": \"Chronos-2\",\n",
    "    \"L\": None,\n",
    "    \"hidden\": None,\n",
    "    \"layers\": None,\n",
    "    \"batch\": None,\n",
    "    \"epochs\": None,\n",
    "    \"lr\": None,\n",
    "    \"rmse_q50\": float(rmse_chronos),\n",
    "    \"pinball_q90\": float(pinball_chronos_q90),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ac1ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 128          # context length (5-min steps)\n",
    "BATCH = 256\n",
    "EPOCHS = 20     # start small\n",
    "LR = 1e-3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc49baf7",
   "metadata": {},
   "source": [
    "we create per-sector sequences (one week each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c08d44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use last_week_df (contains secteur, timestamp, traffic)\n",
    "week_series = (\n",
    "    last_week_df\n",
    "    .sort_values([\"secteur\", \"timestamp\"])\n",
    "    .groupby(\"secteur\")[\"traffic\"]\n",
    "    .apply(lambda s: s.to_numpy(dtype=np.float32))\n",
    ")\n",
    "\n",
    "# we keep only sectors with full week (or at least L+2 points)\n",
    "week_series = week_series[week_series.apply(len) >= (L + 2)]\n",
    "len(week_series)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee253d6",
   "metadata": {},
   "source": [
    "We train windows + test point (last point)\n",
    "\n",
    "For each sector:\n",
    "\n",
    " - train windows predict next-step within the week except last point\n",
    "\n",
    " - test uses the last L points → predict final point (same logic as Chronos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28878786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162282, 128), (86, 128))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = [], []\n",
    "X_test, y_test, test_ids = [], [], []\n",
    "\n",
    "for sid, arr in week_series.items():\n",
    "    n = len(arr)\n",
    "\n",
    "    # training windows: use up to n-1 (leave last for final evaluation)\n",
    "    train_end = n - 1\n",
    "    for t in range(L, train_end):\n",
    "        X_train.append(arr[t-L:t])\n",
    "        y_train.append(arr[t])\n",
    "\n",
    "    # test: last step prediction (t = n-1)\n",
    "    X_test.append(arr[n-1-L:n-1])\n",
    "    y_test.append(arr[n-1])\n",
    "    test_ids.append(sid)\n",
    "\n",
    "X_train = np.stack(X_train)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "X_test  = np.stack(X_test)\n",
    "y_test  = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4686d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N,L,1)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # (N,1)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=BATCH, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c39cc2",
   "metadata": {},
   "source": [
    "Two outputs: q50 and q90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a32304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLSTM(nn.Module):\n",
    "    def __init__(self, hidden=64, layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden, num_layers=layers, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, 2)  # two quantiles\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)          # (B,L,H)\n",
    "        h = out[:, -1, :]              # last state\n",
    "        q = self.head(h)               # (B,2)\n",
    "        return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bcfc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pinball(y, yhat, q):\n",
    "    # y, yhat: (B,)\n",
    "    e = y - yhat\n",
    "    return torch.mean(torch.maximum(q*e, (1-q)*(-e)))\n",
    "\n",
    "def quantile_loss(y, qhat):\n",
    "    # qhat: (B,2) -> [q50, q90]\n",
    "    y = y.squeeze(-1)\n",
    "    q50 = qhat[:, 0]\n",
    "    q90 = qhat[:, 1]\n",
    "    return pinball(y, q50, 0.5) + pinball(y, q90, 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4283172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - loss=48.7488\n",
      "Epoch 2/20 - loss=45.5131\n",
      "Epoch 3/20 - loss=44.0318\n",
      "Epoch 4/20 - loss=43.1740\n",
      "Epoch 5/20 - loss=41.5104\n",
      "Epoch 6/20 - loss=40.1466\n",
      "Epoch 7/20 - loss=39.3231\n",
      "Epoch 8/20 - loss=38.7755\n",
      "Epoch 9/20 - loss=38.3743\n",
      "Epoch 10/20 - loss=38.2931\n",
      "Epoch 11/20 - loss=38.0483\n",
      "Epoch 12/20 - loss=37.8299\n",
      "Epoch 13/20 - loss=37.6920\n",
      "Epoch 14/20 - loss=37.9135\n",
      "Epoch 15/20 - loss=37.7607\n",
      "Epoch 16/20 - loss=37.5951\n",
      "Epoch 17/20 - loss=37.4862\n",
      "Epoch 18/20 - loss=37.7594\n",
      "Epoch 19/20 - loss=37.6235\n",
      "Epoch 20/20 - loss=37.3418\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = QuantileLSTM(hidden=64, layers=1).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        qhat = model(xb)\n",
    "        loss = quantile_loss(yb, qhat)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses.append(loss.item())\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} - loss={np.mean(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e930cd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(113.332886), np.float32(21.210234))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1).to(device)  # (S,L,1)\n",
    "    qhat = model(xb).cpu().numpy()  # (S,2)\n",
    "\n",
    "pred_q50 = qhat[:, 0]\n",
    "pred_q90 = qhat[:, 1]\n",
    "\n",
    "rmse_lstm = np.sqrt(np.mean((pred_q50 - y_test)**2))\n",
    "\n",
    "pinball_lstm_q90 = np.mean(\n",
    "    np.maximum(0.9*(y_test - pred_q90), 0.1*(pred_q90 - y_test))\n",
    ")\n",
    "\n",
    "rmse_lstm, pinball_lstm_q90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7c71aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>RMSE_q50</th>\n",
       "      <th>Pinball_q90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chronos-2</td>\n",
       "      <td>112.951884</td>\n",
       "      <td>21.524749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>113.332886</td>\n",
       "      <td>21.210234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model    RMSE_q50  Pinball_q90\n",
       "0      Chronos-2  112.951884    21.524749\n",
       "1  LSTM-quantile  113.332886    21.210234"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"model\": [\"Chronos-2\", \"LSTM-quantile\"],\n",
    "    \"RMSE_q50\": [rmse_chronos, rmse_lstm],\n",
    "    \"Pinball_q90\": [pinball_chronos_q90, pinball_lstm_q90]\n",
    "})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a88a4b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] L=64 hidden=32 layers=1 epochs=3 -> RMSE=113.333 | Pinball@0.9=36.848\n",
      "[DONE] L=64 hidden=32 layers=1 epochs=5 -> RMSE=113.333 | Pinball@0.9=33.241\n",
      "[DONE] L=64 hidden=32 layers=1 epochs=10 -> RMSE=113.331 | Pinball@0.9=23.834\n",
      "[DONE] L=64 hidden=32 layers=2 epochs=3 -> RMSE=113.327 | Pinball@0.9=36.842\n",
      "[DONE] L=64 hidden=32 layers=2 epochs=5 -> RMSE=113.333 | Pinball@0.9=33.337\n",
      "[DONE] L=64 hidden=32 layers=2 epochs=10 -> RMSE=113.332 | Pinball@0.9=28.487\n",
      "[DONE] L=64 hidden=64 layers=1 epochs=3 -> RMSE=113.330 | Pinball@0.9=31.958\n",
      "[DONE] L=64 hidden=64 layers=1 epochs=5 -> RMSE=113.327 | Pinball@0.9=27.497\n",
      "[DONE] L=64 hidden=64 layers=1 epochs=10 -> RMSE=113.332 | Pinball@0.9=21.578\n",
      "[DONE] L=64 hidden=64 layers=2 epochs=3 -> RMSE=113.333 | Pinball@0.9=32.024\n",
      "[DONE] L=64 hidden=64 layers=2 epochs=5 -> RMSE=113.335 | Pinball@0.9=28.882\n",
      "[DONE] L=64 hidden=64 layers=2 epochs=10 -> RMSE=113.331 | Pinball@0.9=22.795\n",
      "[DONE] L=64 hidden=128 layers=1 epochs=3 -> RMSE=113.276 | Pinball@0.9=27.118\n",
      "[DONE] L=64 hidden=128 layers=1 epochs=5 -> RMSE=113.332 | Pinball@0.9=22.403\n",
      "[DONE] L=64 hidden=128 layers=1 epochs=10 -> RMSE=113.329 | Pinball@0.9=20.961\n",
      "[DONE] L=64 hidden=128 layers=2 epochs=3 -> RMSE=113.327 | Pinball@0.9=28.543\n",
      "[DONE] L=64 hidden=128 layers=2 epochs=5 -> RMSE=113.314 | Pinball@0.9=27.923\n",
      "[DONE] L=64 hidden=128 layers=2 epochs=10 -> RMSE=113.329 | Pinball@0.9=21.911\n",
      "[DONE] L=128 hidden=32 layers=1 epochs=3 -> RMSE=113.328 | Pinball@0.9=36.941\n",
      "[DONE] L=128 hidden=32 layers=1 epochs=5 -> RMSE=113.332 | Pinball@0.9=32.076\n",
      "[DONE] L=128 hidden=32 layers=1 epochs=10 -> RMSE=113.325 | Pinball@0.9=24.181\n",
      "[DONE] L=128 hidden=32 layers=2 epochs=3 -> RMSE=113.327 | Pinball@0.9=37.082\n",
      "[DONE] L=128 hidden=32 layers=2 epochs=5 -> RMSE=113.329 | Pinball@0.9=33.405\n",
      "[DONE] L=128 hidden=32 layers=2 epochs=10 -> RMSE=113.335 | Pinball@0.9=28.609\n",
      "[DONE] L=128 hidden=64 layers=1 epochs=3 -> RMSE=113.328 | Pinball@0.9=32.165\n",
      "[DONE] L=128 hidden=64 layers=1 epochs=5 -> RMSE=113.330 | Pinball@0.9=24.907\n",
      "[DONE] L=128 hidden=64 layers=1 epochs=10 -> RMSE=113.330 | Pinball@0.9=22.559\n",
      "[DONE] L=128 hidden=64 layers=2 epochs=3 -> RMSE=113.330 | Pinball@0.9=32.268\n",
      "[DONE] L=128 hidden=64 layers=2 epochs=5 -> RMSE=113.328 | Pinball@0.9=29.038\n",
      "[DONE] L=128 hidden=64 layers=2 epochs=10 -> RMSE=113.331 | Pinball@0.9=27.839\n",
      "[DONE] L=128 hidden=128 layers=1 epochs=3 -> RMSE=113.336 | Pinball@0.9=25.092\n",
      "[DONE] L=128 hidden=128 layers=1 epochs=5 -> RMSE=113.328 | Pinball@0.9=21.296\n",
      "[DONE] L=128 hidden=128 layers=1 epochs=10 -> RMSE=113.332 | Pinball@0.9=19.492\n",
      "[DONE] L=128 hidden=128 layers=2 epochs=3 -> RMSE=113.327 | Pinball@0.9=27.982\n",
      "[DONE] L=128 hidden=128 layers=2 epochs=5 -> RMSE=113.323 | Pinball@0.9=27.897\n",
      "[DONE] L=128 hidden=128 layers=2 epochs=10 -> RMSE=113.333 | Pinball@0.9=20.755\n",
      "[DONE] L=256 hidden=32 layers=1 epochs=3 -> RMSE=113.329 | Pinball@0.9=37.481\n",
      "[DONE] L=256 hidden=32 layers=1 epochs=5 -> RMSE=113.331 | Pinball@0.9=33.944\n",
      "[DONE] L=256 hidden=32 layers=1 epochs=10 -> RMSE=113.332 | Pinball@0.9=37.321\n",
      "[DONE] L=256 hidden=32 layers=2 epochs=3 -> RMSE=113.330 | Pinball@0.9=37.531\n",
      "[DONE] L=256 hidden=32 layers=2 epochs=5 -> RMSE=113.332 | Pinball@0.9=34.008\n",
      "[DONE] L=256 hidden=32 layers=2 epochs=10 -> RMSE=113.324 | Pinball@0.9=28.926\n",
      "[DONE] L=256 hidden=64 layers=1 epochs=3 -> RMSE=113.322 | Pinball@0.9=32.654\n",
      "[DONE] L=256 hidden=64 layers=1 epochs=5 -> RMSE=113.334 | Pinball@0.9=27.174\n",
      "[DONE] L=256 hidden=64 layers=1 epochs=10 -> RMSE=113.332 | Pinball@0.9=22.276\n",
      "[DONE] L=256 hidden=64 layers=2 epochs=3 -> RMSE=113.334 | Pinball@0.9=32.800\n",
      "[DONE] L=256 hidden=64 layers=2 epochs=5 -> RMSE=113.330 | Pinball@0.9=29.421\n",
      "[DONE] L=256 hidden=64 layers=2 epochs=10 -> RMSE=113.338 | Pinball@0.9=27.801\n",
      "[DONE] L=256 hidden=128 layers=1 epochs=3 -> RMSE=113.330 | Pinball@0.9=24.309\n",
      "[DONE] L=256 hidden=128 layers=1 epochs=5 -> RMSE=113.332 | Pinball@0.9=22.922\n",
      "[DONE] L=256 hidden=128 layers=1 epochs=10 -> RMSE=113.326 | Pinball@0.9=19.901\n",
      "[DONE] L=256 hidden=128 layers=2 epochs=3 -> RMSE=113.330 | Pinball@0.9=28.910\n",
      "[DONE] L=256 hidden=128 layers=2 epochs=5 -> RMSE=113.329 | Pinball@0.9=26.453\n",
      "[DONE] L=256 hidden=128 layers=2 epochs=10 -> RMSE=113.334 | Pinball@0.9=20.695\n",
      "\n",
      "Saved all runs to: results_grid_lstm_quantiles.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "\n",
    "# -------------------------\n",
    "# 0) Logging (CSV)\n",
    "# -------------------------\n",
    "RESULTS_CSV = \"results_grid_lstm_quantiles.csv\"\n",
    "\n",
    "def log_run(row: dict, path=RESULTS_CSV):\n",
    "    row = dict(row)\n",
    "    row[\"run_time\"] = datetime.now().isoformat(timespec=\"seconds\")\n",
    "    df_row = pd.DataFrame([row])\n",
    "    if os.path.exists(path):\n",
    "        df_row.to_csv(path, mode=\"a\", header=False, index=False)\n",
    "    else:\n",
    "        df_row.to_csv(path, mode=\"w\", header=True, index=False)\n",
    "\n",
    "# -------------------------\n",
    "# 1) Dataset helpers\n",
    "# -------------------------\n",
    "class WindowDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)  # (N,L,1)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)  # (N,1)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "\n",
    "def build_windows(week_series, L):\n",
    "    \"\"\"\n",
    "    week_series: pd.Series mapping sector_id -> np.array traffic for last week\n",
    "    Returns: X_train, y_train, X_test, y_test, test_ids\n",
    "    \"\"\"\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test, test_ids = [], [], []\n",
    "\n",
    "    for sid, arr in week_series.items():\n",
    "        n = len(arr)\n",
    "        if n < L + 2:\n",
    "            continue\n",
    "\n",
    "        # training: predict next step within the week, excluding final point\n",
    "        train_end = n - 1\n",
    "        for t in range(L, train_end):\n",
    "            X_train.append(arr[t-L:t])\n",
    "            y_train.append(arr[t])\n",
    "\n",
    "        # test: predict last point\n",
    "        X_test.append(arr[n-1-L:n-1])\n",
    "        y_test.append(arr[n-1])\n",
    "        test_ids.append(sid)\n",
    "\n",
    "    X_train = np.stack(X_train).astype(np.float32)\n",
    "    y_train = np.array(y_train, dtype=np.float32)\n",
    "\n",
    "    X_test  = np.stack(X_test).astype(np.float32)\n",
    "    y_test  = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, test_ids\n",
    "\n",
    "# -------------------------\n",
    "# 2) Model + loss\n",
    "# -------------------------\n",
    "class QuantileLSTM(nn.Module):\n",
    "    def __init__(self, hidden=64, layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden, num_layers=layers, batch_first=True)\n",
    "        self.head = nn.Linear(hidden, 2)  # q50, q90\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]\n",
    "        return self.head(h)\n",
    "\n",
    "def pinball_torch(y, yhat, q):\n",
    "    e = y - yhat\n",
    "    return torch.mean(torch.maximum(q*e, (1-q)*(-e)))\n",
    "\n",
    "def quantile_loss(y, qhat):\n",
    "    y = y.squeeze(-1)\n",
    "    q50 = qhat[:, 0]\n",
    "    q90 = qhat[:, 1]\n",
    "    return pinball_torch(y, q50, 0.5) + pinball_torch(y, q90, 0.9)\n",
    "\n",
    "def eval_metrics(y_true, pred_q50, pred_q90):\n",
    "    rmse = float(np.sqrt(np.mean((pred_q50 - y_true) ** 2)))\n",
    "    pinball_q90 = float(np.mean(np.maximum(0.9*(y_true - pred_q90), 0.1*(pred_q90 - y_true))))\n",
    "    return rmse, pinball_q90\n",
    "\n",
    "# -------------------------\n",
    "# 3) One training run\n",
    "# -------------------------\n",
    "def train_and_eval_one_run(\n",
    "    week_series,\n",
    "    L=128,\n",
    "    hidden=64,\n",
    "    layers=1,\n",
    "    epochs=5,\n",
    "    batch=256,\n",
    "    lr=1e-3,\n",
    "    device=None\n",
    "):\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    X_train, y_train, X_test, y_test, test_ids = build_windows(week_series, L)\n",
    "\n",
    "    train_loader = DataLoader(WindowDataset(X_train, y_train), batch_size=batch, shuffle=True)\n",
    "\n",
    "    model = QuantileLSTM(hidden=hidden, layers=layers).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        losses = []\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad()\n",
    "            qhat = model(xb)\n",
    "            loss = quantile_loss(yb, qhat)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Eval\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xb = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1).to(device)\n",
    "        qhat = model(xb).cpu().numpy()\n",
    "\n",
    "    pred_q50 = qhat[:, 0]\n",
    "    pred_q90 = qhat[:, 1]\n",
    "    rmse, pinball_q90 = eval_metrics(y_test, pred_q50, pred_q90)\n",
    "\n",
    "    return rmse, pinball_q90, int(len(test_ids)), int(len(X_train))\n",
    "\n",
    "# -------------------------\n",
    "# 4) GRID LOOP\n",
    "# -------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "grid_L      = [64, 128, 256]\n",
    "grid_hidden = [32, 64, 128]\n",
    "grid_layers = [1, 2]\n",
    "grid_epochs = [3, 5, 10]\n",
    "grid_lr     = [1e-3]\n",
    "grid_batch  = [256]\n",
    "\n",
    "\n",
    "# log_run({\"model\": \"Chronos-2\", \"rmse_q50\": float(rmse_chronos), \"pinball_q90\": float(pinball_chronos_q90)})\n",
    "\n",
    "for L in grid_L:\n",
    "    for hidden in grid_hidden:\n",
    "        for layers in grid_layers:\n",
    "            for epochs in grid_epochs:\n",
    "                for lr in grid_lr:\n",
    "                    for batch in grid_batch:\n",
    "                        rmse_lstm, pinball_lstm_q90, n_sectors, n_train_windows = train_and_eval_one_run(\n",
    "                            week_series=week_series,\n",
    "                            L=L,\n",
    "                            hidden=hidden,\n",
    "                            layers=layers,\n",
    "                            epochs=epochs,\n",
    "                            batch=batch,\n",
    "                            lr=lr,\n",
    "                            device=device\n",
    "                        )\n",
    "\n",
    "                        log_run({\n",
    "                            \"model\": \"LSTM-quantile\",\n",
    "                            \"L\": L,\n",
    "                            \"hidden\": hidden,\n",
    "                            \"layers\": layers,\n",
    "                            \"epochs\": epochs,\n",
    "                            \"batch\": batch,\n",
    "                            \"lr\": lr,\n",
    "                            \"n_sectors\": n_sectors,\n",
    "                            \"n_train_windows\": n_train_windows,\n",
    "                            \"rmse_q50\": rmse_lstm,\n",
    "                            \"pinball_q90\": pinball_lstm_q90\n",
    "                        })\n",
    "\n",
    "                        print(f\"[DONE] L={L} hidden={hidden} layers={layers} epochs={epochs} \"\n",
    "                              f\"-> RMSE={rmse_lstm:.3f} | Pinball@0.9={pinball_lstm_q90:.3f}\")\n",
    "\n",
    "print(f\"\\nSaved all runs to: {RESULTS_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05786d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>L</th>\n",
       "      <th>hidden</th>\n",
       "      <th>layers</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch</th>\n",
       "      <th>lr</th>\n",
       "      <th>n_sectors</th>\n",
       "      <th>n_train_windows</th>\n",
       "      <th>rmse_q50</th>\n",
       "      <th>pinball_q90</th>\n",
       "      <th>run_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>162282</td>\n",
       "      <td>113.331879</td>\n",
       "      <td>19.492071</td>\n",
       "      <td>2026-02-09T01:03:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>151274</td>\n",
       "      <td>113.326302</td>\n",
       "      <td>19.901014</td>\n",
       "      <td>2026-02-09T07:13:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>151274</td>\n",
       "      <td>113.333725</td>\n",
       "      <td>20.695364</td>\n",
       "      <td>2026-02-09T10:37:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>162282</td>\n",
       "      <td>113.333237</td>\n",
       "      <td>20.755035</td>\n",
       "      <td>2026-02-09T02:51:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>167786</td>\n",
       "      <td>113.328850</td>\n",
       "      <td>20.960730</td>\n",
       "      <td>2026-02-08T21:17:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>162282</td>\n",
       "      <td>113.328461</td>\n",
       "      <td>21.296179</td>\n",
       "      <td>2026-02-09T00:36:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>167786</td>\n",
       "      <td>113.332077</td>\n",
       "      <td>21.578300</td>\n",
       "      <td>2026-02-08T20:25:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>167786</td>\n",
       "      <td>113.329323</td>\n",
       "      <td>21.911261</td>\n",
       "      <td>2026-02-08T22:37:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>151274</td>\n",
       "      <td>113.332382</td>\n",
       "      <td>22.275776</td>\n",
       "      <td>2026-02-09T04:24:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LSTM-quantile</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>0.001</td>\n",
       "      <td>86</td>\n",
       "      <td>167786</td>\n",
       "      <td>113.331657</td>\n",
       "      <td>22.402582</td>\n",
       "      <td>2026-02-08T21:02:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model    L  hidden  layers  epochs  batch     lr  n_sectors  \\\n",
       "32  LSTM-quantile  128     128       1      10    256  0.001         86   \n",
       "50  LSTM-quantile  256     128       1      10    256  0.001         86   \n",
       "53  LSTM-quantile  256     128       2      10    256  0.001         86   \n",
       "35  LSTM-quantile  128     128       2      10    256  0.001         86   \n",
       "14  LSTM-quantile   64     128       1      10    256  0.001         86   \n",
       "31  LSTM-quantile  128     128       1       5    256  0.001         86   \n",
       "8   LSTM-quantile   64      64       1      10    256  0.001         86   \n",
       "17  LSTM-quantile   64     128       2      10    256  0.001         86   \n",
       "44  LSTM-quantile  256      64       1      10    256  0.001         86   \n",
       "13  LSTM-quantile   64     128       1       5    256  0.001         86   \n",
       "\n",
       "    n_train_windows    rmse_q50  pinball_q90             run_time  \n",
       "32           162282  113.331879    19.492071  2026-02-09T01:03:09  \n",
       "50           151274  113.326302    19.901014  2026-02-09T07:13:33  \n",
       "53           151274  113.333725    20.695364  2026-02-09T10:37:08  \n",
       "35           162282  113.333237    20.755035  2026-02-09T02:51:46  \n",
       "14           167786  113.328850    20.960730  2026-02-08T21:17:35  \n",
       "31           162282  113.328461    21.296179  2026-02-09T00:36:55  \n",
       "8            167786  113.332077    21.578300  2026-02-08T20:25:04  \n",
       "17           167786  113.329323    21.911261  2026-02-08T22:37:59  \n",
       "44           151274  113.332382    22.275776  2026-02-09T04:24:49  \n",
       "13           167786  113.331657    22.402582  2026-02-08T21:02:39  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv(RESULTS_CSV)\n",
    "runs.sort_values(\"pinball_q90\").head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d15448",
   "metadata": {},
   "source": [
    "# AUGMENTATION section 6(a)/(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec955fca",
   "metadata": {},
   "source": [
    "We followed Section II-C by generating instantaneous traffic via an Interrupted Poisson Process (IPP) with ON/OFF dynamics. Parameters \n",
    "𝜏\n",
    ",\n",
    "𝜁\n",
    "τ,ζ control burst duration; \n",
    "𝜆\n",
    "λ and \n",
    "𝐸\n",
    "(\n",
    "𝜓\n",
    ")\n",
    "E(ψ) are derived from the target mean and variance using the paper’s closed-form equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eef9f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 300        # 5 minutes in seconds\n",
    "dt = 5.0       # generate one value every 5 seconds -> 60 points per row\n",
    "tau, zeta = 0.1, 0.5\n",
    "alpha = 0.5    # std = alpha * mean (you can tune)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "547863d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ipp_window(mu, sigma2, T=300, dt=1.0, tau=0.1, zeta=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Paper-style traffic generation for one averaging window of duration T seconds.\n",
    "    mu     = E(Psi) target mean over the window\n",
    "    sigma2 = Var(Psi) target variance over the window\n",
    "    tau, zeta = OFF->ON and ON->OFF transition rates (1/sec)\n",
    "    dt = time resolution for the generated instantaneous series (sec)\n",
    "    Returns: instantaneous array of length int(T/dt)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = int(T / dt)\n",
    "\n",
    "    if mu <= 0:\n",
    "        return np.zeros(n, dtype=np.float32)\n",
    "\n",
    "    # Eq (11): lambda (arrival rate in ON state)\n",
    "    term = (sigma2 / (mu**2)) - (2 * zeta) / (tau * T * (tau + zeta))\n",
    "    if term <= 0:\n",
    "        # infeasible region (Fig 6c). Clamp so it still runs.\n",
    "        term = 1e-6\n",
    "\n",
    "    lam = (tau + zeta) / (tau * T) * term  # arrivals per second (ON state)\n",
    "\n",
    "    # Eq (12): mean per-arrival demand E(psi)\n",
    "    Epsi = (tau + zeta) * mu / (tau * lam * T)\n",
    "\n",
    "    # Discrete-time Markov ON/OFF from continuous rates\n",
    "    p_on_to_off  = 1 - np.exp(-zeta * dt)\n",
    "    p_off_to_on  = 1 - np.exp(-tau  * dt)\n",
    "\n",
    "    # initial state from steady-state\n",
    "    p_on = tau / (tau + zeta)\n",
    "    on = rng.random() < p_on\n",
    "\n",
    "    x = np.zeros(n, dtype=np.float32)\n",
    "\n",
    "    for t in range(n):\n",
    "        # state transition\n",
    "        if on:\n",
    "            if rng.random() < p_on_to_off:\n",
    "                on = False\n",
    "        else:\n",
    "            if rng.random() < p_off_to_on:\n",
    "                on = True\n",
    "\n",
    "        # arrivals + demand\n",
    "        if on:\n",
    "            U = rng.poisson(lam * dt)  # arrivals in this dt slice\n",
    "            if U > 0:\n",
    "                psi = rng.exponential(scale=Epsi, size=U)\n",
    "                x[t] = psi.sum()\n",
    "    m = x.mean()\n",
    "    if m > 0:\n",
    "        x = x * (mu / m)\n",
    "    else:\n",
    "        x[:] = 0.0\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a71c0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.0), 0.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 300          # 5 minutes\n",
    "dt = 5.0         # generate every 5 seconds (60 points per 5 minutes)\n",
    "tau, zeta = 0.1, 0.5\n",
    "alpha = 0.5      # controls burstiness via variance (you can tune)\n",
    "\n",
    "def generate_instantaneous_from_avg(mu):\n",
    "    sigma2 = (alpha * mu)**2\n",
    "    return ipp_window(mu=mu, sigma2=sigma2, T=T, dt=dt, tau=tau, zeta=zeta)\n",
    "\n",
    "# Example: one row\n",
    "mu = float(df.loc[0, \"trafic_mbps\"])\n",
    "inst = generate_instantaneous_from_avg(mu)\n",
    "inst.mean(), mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "297bd99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secteur</th>\n",
       "      <th>site</th>\n",
       "      <th>tstamp_avg</th>\n",
       "      <th>k</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-12 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-12 00:00:05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-12 00:00:10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-12 00:00:15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T36870A</td>\n",
       "      <td>T36870</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-12 00:00:20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   secteur    site tstamp_avg  k           timestamp  traffic\n",
       "0  T36870A  T36870 2018-11-12  0 2018-11-12 00:00:00      0.0\n",
       "1  T36870A  T36870 2018-11-12  1 2018-11-12 00:00:05      0.0\n",
       "2  T36870A  T36870 2018-11-12  2 2018-11-12 00:00:10      0.0\n",
       "3  T36870A  T36870 2018-11-12  3 2018-11-12 00:00:15      0.0\n",
       "4  T36870A  T36870 2018-11-12  4 2018-11-12 00:00:20      0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instantaneous_rows = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    mu = float(row[\"trafic_mbps\"])\n",
    "    sigma2 = (alpha * mu) ** 2\n",
    "\n",
    "    inst = ipp_window(mu=mu, sigma2=sigma2, T=T, dt=dt, tau=tau, zeta=zeta)\n",
    "\n",
    "    # timestamps inside this 5-min window\n",
    "    base_ts = row[\"tstamp\"]\n",
    "    n = len(inst)\n",
    "\n",
    "    for k in range(n):\n",
    "        instantaneous_rows.append({\n",
    "            \"secteur\": row[\"secteur\"],\n",
    "            \"site\": row[\"site\"],\n",
    "            \"tstamp_avg\": base_ts,                          # original 5-min average time\n",
    "            \"k\": k,\n",
    "            \"timestamp\": base_ts + pd.to_timedelta(k*dt, unit=\"s\"),\n",
    "            \"traffic\": float(inst[k])\n",
    "        })\n",
    "\n",
    "instantaneous_df = pd.DataFrame(instantaneous_rows)\n",
    "instantaneous_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee737d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.448600e+04\n",
       "mean    -1.632953e+01\n",
       "std      2.131940e+01\n",
       "min     -1.928720e+02\n",
       "25%     -2.442114e+01\n",
       "50%     -9.258292e+00\n",
       "75%     -9.866886e-07\n",
       "max      1.313854e-05\n",
       "Name: error, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = (\n",
    "    instantaneous_df.groupby([\"secteur\", \"tstamp_avg\"])[\"traffic\"].mean()\n",
    "    .reset_index()\n",
    "    .merge(df[[\"secteur\", \"tstamp\", \"trafic_mbps\"]],\n",
    "           left_on=[\"secteur\", \"tstamp_avg\"],\n",
    "           right_on=[\"secteur\", \"tstamp\"],\n",
    "           how=\"left\")\n",
    ")\n",
    "\n",
    "check[\"error\"] = check[\"traffic\"] - check[\"trafic_mbps\"]\n",
    "check[\"error\"].describe()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
