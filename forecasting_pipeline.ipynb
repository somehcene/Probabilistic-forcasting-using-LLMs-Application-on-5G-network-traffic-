{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Pipeline: LSTM vs Chronos2\n",
    "\n",
    "In this notebook, we load the aggregated, fine-grained IPP synthesized 6G network traffic data, and we train a PyTorch LSTM model alongside a zero-shot evaluation on Amazon's Chronos2 Foundation Model.\n",
    "\n",
    "We then plot the results to visually understand their forecasting capabilities on micro-bursts vs macro trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.data_loader import load_and_aggregate_data, get_synthesized_data, prepare_dataloaders\n",
    "from src.models.lstm import TrafficLSTM, train_model\n",
    "from src.models.chronos_wrapper import get_chronos_forecast\n",
    "from src.evaluate import calculate_metrics, print_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare 6G Traffic Data\n",
    "We use the fine-grained data mapped via Continuous-Time Markov Chain IPP logic to capture real network volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load empirical data and synthesize fine-grained IPP data\n",
    "df_agg = load_and_aggregate_data()\n",
    "fine_data = get_synthesized_data(df_agg, dt=60.0)\n",
    "\n",
    "# Set Forecasting Window Specs\n",
    "SEQ_LENGTH = 60    # 60 past points \n",
    "PRED_LENGTH = 12   # 12 future points\n",
    "\n",
    "# Create Datasets and Loaders\n",
    "train_loader, val_loader, test_loader, scaler, train_scaled, val_scaled, test_scaled = prepare_dataloaders(\n",
    "    fine_data, \n",
    "    seq_length=SEQ_LENGTH, \n",
    "    pred_length=PRED_LENGTH, \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(f\"Data Lengths -> Train: {len(train_scaled)} | Val: {len(val_scaled)} | Test: {len(test_scaled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch LSTM Model Training\n",
    "Here we train the LSTM to identify the historical sequential dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "lstm_model = TrafficLSTM(\n",
    "    input_size=1, \n",
    "    hidden_layer_size=64, \n",
    "    num_layers=2, \n",
    "    output_size=PRED_LENGTH\n",
    ")\n",
    "\n",
    "# Train (Uncomment to train - requires a few minutes depending on CPU/GPU)\n",
    "# lstm_model = train_model(\n",
    "#     lstm_model, \n",
    "#     train_loader, \n",
    "#     val_loader, \n",
    "#     epochs=30, \n",
    "#     patience=5, \n",
    "#     device=device\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation and Visualization on Test Data\n",
    "We evaluate a slice of the test data (e.g., pulling a random batch) and compare LSTM and Chronos zero-shot capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take the very first batch of the test data for evaluation & plotting\n",
    "lstm_model.eval()\n",
    "test_seq, test_labels = next(iter(test_loader))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # LSTM Prediction\n",
    "    lstm_preds = lstm_model(test_seq.to(device)).cpu().numpy()\n",
    "\n",
    "    # Chronos Prediction\n",
    "    # Chronos expects the context data. Removing the feature dim (since it's only 1 feature)\n",
    "    chronos_preds = get_chronos_forecast(test_seq.squeeze(-1), pred_length=PRED_LENGTH, model_id=\"amazon/chronos-t5-small\")\n",
    "    \n",
    "    # Evaluate on the first sample in the batch\n",
    "    idx = 0\n",
    "    actual = scaler.inverse_transform(test_labels[idx].numpy())\n",
    "    lstm_pred_unscaled = scaler.inverse_transform(lstm_preds[idx].reshape(-1, 1))\n",
    "    chronos_pred_unscaled = scaler.inverse_transform(chronos_preds[idx].reshape(-1, 1))\n",
    "\n",
    "    # Metrics\n",
    "    lstm_metrics = calculate_metrics(actual, lstm_pred_unscaled)\n",
    "    chronos_metrics = calculate_metrics(actual, chronos_pred_unscaled)\n",
    "    \n",
    "    print_metrics(\"LSTM\", lstm_metrics)\n",
    "    print_metrics(\"Chronos2\", chronos_metrics)\n",
    "\n",
    "    # ---- PLOTTING ----\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    context_len = len(test_seq[idx])\n",
    "    x_context = np.arange(context_len)\n",
    "    x_pred = np.arange(context_len, context_len + PRED_LENGTH)\n",
    "    \n",
    "    # Plot Past Context\n",
    "    plt.plot(x_context, scaler.inverse_transform(test_seq[idx].numpy()), label=\"Past Context\", color='black', alpha=0.7)\n",
    "    \n",
    "    # Plot Actual Ground Truth\n",
    "    plt.plot(x_pred, actual, label=\"Ground Truth\", linestyle='--', color='black', marker='o')\n",
    "\n",
    "    # Plot LSTM\n",
    "    plt.plot(x_pred, lstm_pred_unscaled, label=\"LSTM Forecast\", color='tab:red', marker='x')\n",
    "    \n",
    "    # Plot Chronos2\n",
    "    plt.plot(x_pred, chronos_pred_unscaled, label=\"Chronos2 Zero-Shot\", color='tab:blue', marker='s')\n",
    "\n",
    "    plt.title(\"Forecasting Comparison: LSTM vs Amazon Chronos2 (Small)\")\n",
    "    plt.xlabel(\"Time Steps\")\n",
    "    plt.ylabel(\"Traffic Demand (Mbps)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}